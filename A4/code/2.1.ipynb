{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to run code successfully please upload the data set_a, set B, code 2.1, 2.2 and 2.3 in one folder of jupyter notebook.\n",
    "## For question 2.1 the output is the in form of word. Prentropy is the entropy befroe split. And the entropy is that after split. The index 0,1,2,3 denotes feature sepal length (cm)', 'sepal width (cm)', 'petal length (cm)' and 'petal width (cm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三种鸢尾花的数量分别为： [21. 25. 54.]\n",
      "三种莺尾花的概率为： [0.21 0.25 0.54]\n",
      "鸢尾花的熵为： 1.4528662323792307\n",
      "鸢尾花默认的信息熵 ： 1.4528662323792307\n",
      "带花瓣宽度的条件熵 ： 0.9399241705336179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "iris = pd.read_csv('set_a.csv',header=None)\n",
    "\n",
    "# 数据特征：150行， 4列\n",
    "features=iris.iloc[:,0:4].values\n",
    "target=iris.iloc[:,4].values\n",
    "target=target.astype(int)\n",
    "\n",
    "iris.feature_names=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "feature_names=iris.feature_names\n",
    "iris.target_names=['0','1','2']\n",
    "class_names = iris.target_names\n",
    "\n",
    "iris_count = np.zeros(3)\n",
    "\n",
    "iris_count[0] = target[target == 0].size\n",
    "iris_count[1] = target[target == 1].size\n",
    "iris_count[2] = target[target == 2].size\n",
    "\n",
    "print(\"三种鸢尾花的数量分别为：\", iris_count)\n",
    "\n",
    "# 计算每种鸢尾花的概率\n",
    "iris_probability = np.divide(iris_count, 100)\n",
    "\n",
    "print(\"三种莺尾花的概率为：\", iris_probability)\n",
    "\n",
    "# 根据公式算出鸢尾花的熵：\n",
    "iris_h = -np.sum(iris_probability * np.log2(iris_probability))\n",
    "\n",
    "print(\"鸢尾花的熵为：\", iris_h)\n",
    "\n",
    "def calcEntropy(target):\n",
    "    label = np.unique(target)\n",
    "    n = label.size\n",
    "    count = np.zeros(n)\n",
    "    p_i = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        count[i] = target[target == label[i]].size\n",
    "    \n",
    "    # 计算每个类别的概率\n",
    "    p_i = np.divide(count, target.size)\n",
    "    \n",
    "    # 计算熵\n",
    "    entropy = 0\n",
    "    for i in range(n):\n",
    "        entropy = entropy - p_i[i] * np.log2(p_i[i])\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def calcConditionEntropy(feature, condition, target):\n",
    "    true_condition = condition(feature)\n",
    "    false_condition = true_condition == False\n",
    "    target_true = target[true_condition]\n",
    "    target_false = target[false_condition]\n",
    "    # 每种属性类别的数量除以总数就计算出其概率\n",
    "    p_true = target_true.size / target.size\n",
    "    p_false = 1 - p_true\n",
    "    # 每种属性类别的概率乘以该类别下的信息熵\n",
    "    entropy = p_true * calcEntropy(target_true) + p_false * calcEntropy(target_false)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "# 重新使用函数计算一次鸢尾花的熵，结果跟上面一样\n",
    "H = calcEntropy(target)\n",
    "\n",
    "# 加入鸢尾花花瓣宽度属性后，计算鸢尾花的条件熵\n",
    "petal_length = features[:,2]\n",
    "HC = calcConditionEntropy(petal_length, lambda feature: feature <= 2.45, target)\n",
    "print('鸢尾花默认的信息熵 ：', H)\n",
    "print('带花瓣宽度的条件熵 ：', HC)\n",
    "\n",
    "def generate_feature_points(feature, target):\n",
    "    \"\"\"\n",
    "    生成特征的所有分界点: 先对特征进行排序，然后将 target 有变动的地方作为分界点\n",
    "    :param feature: 一维数组，一个特征的样本数据\n",
    "    :param target: 一维数组，数字或者字符串的分类标签\n",
    "    :return: 包含所有分界点的一维数组\n",
    "    \"\"\"\n",
    "\n",
    "    argsort = feature.argsort()\n",
    "    f1 = feature[argsort]\n",
    "    t1 = target[argsort]\n",
    "\n",
    "    last_value = target[0]\n",
    "    split_value = []\n",
    "\n",
    "    # 找出所有分裂点\n",
    "    for i in range(t1.size):\n",
    "        if last_value != t1[i]:\n",
    "            split_value.append((f1[i] + f1[i - 1]) / 2)\n",
    "            last_value = t1[i]\n",
    "\n",
    "    return np.array(split_value)\n",
    "\n",
    "\n",
    "def calc_feature_entropy(feature, target):\n",
    "    \"\"\"\n",
    "    计算一个特征的所有分界点的条件熵，返回最小的那个条件熵（条件熵越小，信息增益越大）\n",
    "    :param feature: 一维数组，一个特征的样本数据\n",
    "    :param target: 一维数组，数字或者字符串的分类标签\n",
    "    :return: 分界点和条件熵\n",
    "    \"\"\"\n",
    "    min_entropy = float('inf')\n",
    "    min_point = 0\n",
    "    prentropy=calcEntropy(target)\n",
    "    points = generate_feature_points(feature, target)\n",
    "    for p in points:\n",
    "        entropy = calcConditionEntropy(feature, lambda f: f <= p, target)\n",
    "        if entropy < min_entropy:\n",
    "            min_entropy = entropy\n",
    "            min_point = p\n",
    "\n",
    "    '没有分界点说明只有一类数据标签，熵为0'\n",
    "    if points.size == 0:\n",
    "        min_entropy = 0\n",
    "\n",
    "    return min_point, min_entropy,prentropy\n",
    "\n",
    "calc_feature_entropy(features[:,2], target)\n",
    "\n",
    "def select_feature(features, target):\n",
    "    \"\"\"\n",
    "    从所有特征中选择出条件熵最小的特征（即最大增益）\n",
    "    :param features: 二维数据，包含所有特征的样本数据\n",
    "    :param target: 一维数组，数字或者字符串的分类标签\n",
    "    :return: 特征索引，条件熵，特征分界点\n",
    "    \"\"\"\n",
    "    min_entropy = float('inf')\n",
    "    min_point = 0\n",
    "    num = features.shape[1]\n",
    "    index = 0\n",
    "    for i in range(num):\n",
    "        point, entropy,prentropy1 = calc_feature_entropy(features[:, i], target)\n",
    "        if entropy <= min_entropy:\n",
    "            index = i\n",
    "            min_point = point\n",
    "            min_entropy = entropy\n",
    "            prentropy=prentropy1\n",
    "\n",
    "    return index, min_point, min_entropy,prentropy\n",
    "\n",
    "class TreeNode:\n",
    "    \n",
    "    feature_index = ''\n",
    "    feature_point = 0\n",
    "    feature_entropy = 0\n",
    "    target_label = ''\n",
    "    true_node = None\n",
    "    false_node = None\n",
    "    feature_right = ''\n",
    "    target_right = ''\n",
    "    feature_left = ''\n",
    "    target_left = ''\n",
    "    right_entropy=0\n",
    "    leaft_entropy=0\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def decision(feature, point):\n",
    "        return feature < point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build tree node index 2, point 2.450000, entropy 0.939924,prentropy 1.452866 \n",
      "build tree node index 1, point 3.050000, entropy 0.631921,prentropy 0.721928 \n",
      "build tree node index 2, point 1.150000, entropy 0.723983,prentropy 0.831474 \n",
      "build tree node index 1, point 3.200000, entropy 0.634945,prentropy 0.764205 \n",
      "build tree node index 0, point 5.150000, entropy 0.595973,prentropy 0.672295 \n",
      "build tree node index 0, point 5.250000, entropy 0.600021,prentropy 0.779350 \n",
      "build tree node index 2, point 1.550000, entropy 0.404563,prentropy 0.650022 \n",
      "build tree node index 3, point 1.750000, entropy 0.550978,prentropy 0.970951 \n",
      "build tree node index 3, point 1.250000, entropy 0.666667,prentropy 0.918296 \n",
      "build tree node index 3, point 0.650000, entropy 0.000000,prentropy 1.000000 \n",
      "build tree node, index 3,  right_entropy 0.000000 \n",
      "build tree node, index 3,  left_entropy 0.000000 \n",
      "build tree node index 2, point 4.550000, entropy 0.775622,prentropy 1.012590 \n",
      "build tree node index 3, point 1.650000, entropy 0.393563,prentropy 0.959687 \n",
      "build tree node index 0, point 5.950000, entropy 0.000000,prentropy 0.787127 \n",
      "build tree node, index 0,  right_entropy 0.000000 \n",
      "build tree node, index 0,  left_entropy 0.000000 \n",
      "build tree node index 0, point 6.650000, entropy 0.518400,prentropy 0.622984 \n",
      "build tree node index 0, point 6.350000, entropy 0.392130,prentropy 0.634310 \n",
      "build tree node index 2, point 4.800000, entropy 0.339135,prentropy 0.426229 \n",
      "build tree node index 3, point 2.000000, entropy 0.000000,prentropy 1.000000 \n",
      "build tree node, index 3,  right_entropy 0.000000 \n",
      "build tree node, index 3,  left_entropy 0.000000 \n",
      "build tree node index 2, point 6.500000, entropy 0.197224,prentropy 0.276195 \n",
      "build tree node index 1, point 2.150000, entropy 0.000000,prentropy 0.591673 \n",
      "build tree node, index 1,  right_entropy 0.000000 \n",
      "build tree node, index 1,  left_entropy 0.000000 \n",
      "build tree node index 3, point 1.050000, entropy 0.225603,prentropy 0.337290 \n",
      "build tree node index 3, point 0.850000, entropy 0.000000,prentropy 0.721928 \n",
      "build tree node, index 3,  right_entropy 0.000000 \n",
      "build tree node, index 3,  left_entropy 0.000000 \n"
     ]
    }
   ],
   "source": [
    "def build_tree(features, target):\n",
    "    \"\"\"\n",
    "    递归构建决策树\n",
    "    :param features: 二维数据，包含所有特征的样本数据\n",
    "    :param target: 一维数组，数字或者字符串的分类标签\n",
    "    :param idn: 决策树节点 id，通过 id 观察决策树计算过程\n",
    "    :return: 决策树根节点\n",
    "    \"\"\"\n",
    "    node = TreeNode()\n",
    "\n",
    "    '选择条件熵最小的特征'\n",
    "    index, point, entropy,prentropy = select_feature(features, target)\n",
    "    \n",
    "    node.feature_index = index\n",
    "    node.feature_point = point\n",
    "    node.feature_entropy = entropy\n",
    "    node.feature_prentropy=prentropy\n",
    "    \n",
    "    print('build tree node index %d, point %f, entropy %f,prentropy %f ' %\n",
    "          ( index, point, entropy,prentropy))\n",
    "   \n",
    "    \n",
    "    \n",
    "    f_copy = features.copy()\n",
    "    t_copy = target.copy()\n",
    "    f = f_copy[:, index]\n",
    "    selector = node.decision(f, point)\n",
    "    \n",
    "    \n",
    "    left_entropy=calcEntropy(t_copy[selector])\n",
    "    right_entropy=calcEntropy(t_copy[selector == False])\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    if left_entropy == 0 and right_entropy != 0:\n",
    "        #print('build tree node, index %d, entropy %f ' %\n",
    "         # ( index ,left_entropy),'left=0')\n",
    "        #print('right','i value',i)\n",
    "        build_tree(f_copy[selector == False], t_copy[selector == False])\n",
    "        #print('split right')\n",
    "        \n",
    "    elif right_entropy == 0 and left_entropy != 0:\n",
    "        #print('build tree node, index %d,  entropy %f ' %\n",
    "          #( index, right_entropy),'right=0')\n",
    "        #print('left','i value',i)\n",
    "        build_tree(f_copy[selector, :], t_copy[selector])\n",
    "        \n",
    "    elif right_entropy != 0 and left_entropy !=0:\n",
    "       \n",
    "        #print('generate left node from not 0')\n",
    "        #print(node.point,'1')\n",
    "        build_tree(f_copy[selector, :], t_copy[selector])\n",
    "        \n",
    "        \n",
    "        #print('generate right node from not0')\n",
    "        #print(node.point,'2')\n",
    "        build_tree(f_copy[selector == False], t_copy[selector == False])\n",
    "        #print(node.point,'3')\n",
    "        \n",
    "    \n",
    "    elif right_entropy == 0 and left_entropy ==0:\n",
    "        print('build tree node, index %d,  right_entropy %f ' %\n",
    "          ( index, right_entropy))\n",
    "        print('build tree node, index %d,  left_entropy %f ' %\n",
    "          ( index, right_entropy))\n",
    "        return node     \n",
    "#'构建决策树，节点编号从 1 开始，深度优先递归方式创建树'\n",
    "clf=build_tree(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
